{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54293e0",
   "metadata": {},
   "source": [
    "# 1. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "818bf8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_forecasting as pf\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import (ConcatDataset, DataLoader, Dataset, Subset,\n",
    "                              random_split)\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c1ea3d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+-------------+---------+-----------+---------+-----------+\n",
      "|    | TIMESTAMP     |   TARGETVAR |     U10 |       V10 |    U100 |      V100 |\n",
      "|----+---------------+-------------+---------+-----------+---------+-----------|\n",
      "|  0 | 20120101 1:00 |   0         | 2.1246  | -2.68197  | 2.86428 | -3.66608  |\n",
      "|  1 | 20120101 2:00 |   0.0548791 | 2.52169 | -1.79696  | 3.34486 | -2.46476  |\n",
      "|  2 | 20120101 3:00 |   0.110234  | 2.67221 | -0.822516 | 3.50845 | -1.21409  |\n",
      "|  3 | 20120101 4:00 |   0.165116  | 2.4575  | -0.143642 | 3.21523 | -0.355546 |\n",
      "|  4 | 20120101 5:00 |   0.15694   | 2.2459  |  0.389576 | 2.95768 |  0.332701 |\n",
      "+----+---------------+-------------+---------+-----------+---------+-----------+\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\User\\Downloads\\WindPowerForecastingData TASK.xlsx\\WindPowerForecastingData TASK.xlsx\"\n",
    "data = pd.read_excel(path, engine='openpyxl')\n",
    "print(tabulate(data.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "61e976aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+---------+-----------+---------+-----------+\n",
      "| TIMESTAMP           |   TARGETVAR |     U10 |       V10 |    U100 |      V100 |\n",
      "|---------------------+-------------+---------+-----------+---------+-----------|\n",
      "| 2012-01-01 01:00:00 |   0         | 2.1246  | -2.68197  | 2.86428 | -3.66608  |\n",
      "| 2012-01-01 02:00:00 |   0.0548791 | 2.52169 | -1.79696  | 3.34486 | -2.46476  |\n",
      "| 2012-01-01 03:00:00 |   0.110234  | 2.67221 | -0.822516 | 3.50845 | -1.21409  |\n",
      "| 2012-01-01 04:00:00 |   0.165116  | 2.4575  | -0.143642 | 3.21523 | -0.355546 |\n",
      "| 2012-01-01 05:00:00 |   0.15694   | 2.2459  |  0.389576 | 2.95768 |  0.332701 |\n",
      "+---------------------+-------------+---------+-----------+---------+-----------+\n"
     ]
    }
   ],
   "source": [
    "data['TIMESTAMP'] = pd.to_datetime(data['TIMESTAMP'])\n",
    "data = data.set_index('TIMESTAMP')\n",
    "print(tabulate(data.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7fe2ea89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 10059\n",
      "Validation size: 3353\n",
      "Test size: 3353\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to tensor (dropping NaNs for simplicity)\n",
    "data_tensor = torch.tensor(data.dropna().values, dtype=torch.float32)\n",
    "\n",
    "# Calculate sizes\n",
    "total_size = len(data_tensor)\n",
    "train_size = int(total_size * 0.6)\n",
    "val_size = int(total_size * 0.2)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Validation size: {val_size}\")\n",
    "print(f\"Test size: {test_size}\")\n",
    "\n",
    "# Create TensorDataset\n",
    "dataset = TensorDataset(data_tensor)\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e2a635d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 10059\n",
      "Validation size: 3353\n",
      "Test size: 3353\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation size: {len(val_loader.dataset)}\")\n",
    "print(f\"Test size: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ffd9ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGETVAR</th>\n",
       "      <th>U10</th>\n",
       "      <th>V10</th>\n",
       "      <th>U100</th>\n",
       "      <th>V100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16765.000000</td>\n",
       "      <td>16800.000000</td>\n",
       "      <td>16800.000000</td>\n",
       "      <td>16800.000000</td>\n",
       "      <td>16800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.303185</td>\n",
       "      <td>0.935519</td>\n",
       "      <td>-0.250466</td>\n",
       "      <td>1.568721</td>\n",
       "      <td>-0.554659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.289702</td>\n",
       "      <td>2.556424</td>\n",
       "      <td>2.919984</td>\n",
       "      <td>4.266318</td>\n",
       "      <td>5.028343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.494252</td>\n",
       "      <td>-9.993858</td>\n",
       "      <td>-10.910809</td>\n",
       "      <td>-15.294866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.063340</td>\n",
       "      <td>-1.062387</td>\n",
       "      <td>-2.337600</td>\n",
       "      <td>-1.746650</td>\n",
       "      <td>-4.613866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.206841</td>\n",
       "      <td>0.788789</td>\n",
       "      <td>-0.039825</td>\n",
       "      <td>1.487808</td>\n",
       "      <td>0.132922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.479184</td>\n",
       "      <td>2.585812</td>\n",
       "      <td>1.927597</td>\n",
       "      <td>4.682327</td>\n",
       "      <td>3.488219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.117029</td>\n",
       "      <td>9.508798</td>\n",
       "      <td>16.988418</td>\n",
       "      <td>14.314416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TARGETVAR           U10           V10          U100          V100\n",
       "count  16765.000000  16800.000000  16800.000000  16800.000000  16800.000000\n",
       "mean       0.303185      0.935519     -0.250466      1.568721     -0.554659\n",
       "std        0.289702      2.556424      2.919984      4.266318      5.028343\n",
       "min        0.000000     -7.494252     -9.993858    -10.910809    -15.294866\n",
       "25%        0.063340     -1.062387     -2.337600     -1.746650     -4.613866\n",
       "50%        0.206841      0.788789     -0.039825      1.487808      0.132922\n",
       "75%        0.479184      2.585812      1.927597      4.682327      3.488219\n",
       "max        1.000000     11.117029      9.508798     16.988418     14.314416"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49908183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wind-tft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
